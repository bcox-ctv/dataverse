import requests
from msal import ConfidentialClientApplication
import os
import pandas as pd
from definitions import definitions_dict  # Import the dictionary from definitions.py

def get_access_token(client_id, tenant_id, client_secret, scope):
    """
    Authenticate using MSAL and get an access token for Dataverse.

    :param client_id: Azure AD Application (client) ID.
    :param tenant_id: Azure AD Tenant ID.
    :param client_secret: Azure AD Application (client) secret.
    :param scope: Scope for the Dataverse API.
    :return: Access token.
    """
    authority = f"https://login.microsoftonline.com/{tenant_id}"

    app = ConfidentialClientApplication(client_id, client_secret, authority)

    # Acquire token using client credentials
    result = app.acquire_token_for_client(scopes=[scope])
    if "access_token" in result:
        return result["access_token"]
    else:
        raise Exception("Failed to acquire access token.")


def fetch_data(endpoint, headers):
    """
    Fetch data from a given API endpoint.

    Args:
        endpoint (str): The API endpoint URL.
        headers (dict): The headers for the API request.

    Returns:
        dict: The JSON response from the API.

    Raises:
        requests.exceptions.RequestException: If the request fails.
    """
    response = requests.get(endpoint, headers=headers)
    response.raise_for_status()
    return response.json()



def process_fields(fields, definitions_dict):
    """
    Process and filter entity fields.

    Args:
        fields (list): List of fields to process.
        definitions_dict (dict): Dictionary of field definitions.

    Returns:
        list: Processed and filtered fields.
    """
    filtered_fields = [
        {
            "ColumnNumber": field.get("ColumnNumber"),
            "PrimaryId": field.get("IsPrimaryId", "") if field.get("IsPrimaryId", False) else "",
            "FieldName": field.get("SchemaName"),  # Changed LogicalName to FieldName and used SchemaName
            "AttributeType": field.get("AttributeType"),
            "Definition": field.get("DisplayName", {}).get("UserLocalizedLabel", {}).get("Label", "") if field.get("DisplayName", {}).get("UserLocalizedLabel") else "",
            "LinkedTable": ", ".join(field.get("Targets", []))  # Convert list of targets to comma-delimited string
        }
        for field in fields
    ]

    for field in filtered_fields:
        logical_name = field.get("LogicalName", "").lower()
        if "yominame" in logical_name:
            field["Definition"] = "Fields for entering the phonetic equivalent for names : Field unused and automatically generated by Dataverse"
        else:
            field["Definition"] = field.get("Definition") or definitions_dict.get(field.get("LogicalName"), "")

    return filtered_fields


def export_dataverse_schema(dataverse_url, access_token, output_file):
    """
    Exports the metadata schema of a Dataverse instance.

    :param dataverse_url: Base URL of the Dataverse instance (e.g., 'https://yourorg.crm.dynamics.com').
    :param access_token: Access token for authentication.
    :param output_file: Path to the output JSON file.
    """
    headers = {
        'Authorization': f'Bearer {access_token}',
        'Accept': 'application/json'
    }
    endpoint = f"{dataverse_url}/api/data/v9.1"

    try:
        # Fetch solution components to filter entities by solution
        solution_name = "EDWP_POC"
        solution_components_action = f"solutions?$filter=uniquename eq '{solution_name}'"
        solution_data = fetch_data(f"{endpoint}/{solution_components_action}", headers)

        # Extract logical names of entities in the solution
        # Fetch solution components separately using the correct endpoint
        solution_id = solution_data.get("value", [])[0].get("solutionid")
        if not solution_id:
            raise Exception(f"Solution '{solution_name}' not found.")

        solution_components_action = f"solutioncomponents?$filter=_solutionid_value eq {solution_id} and componenttype eq 1"
        solution_components_data = fetch_data(f"{endpoint}/{solution_components_action}", headers)

        # Extract logical names of entities in the solution
        solution_entity_logical_names = [
            component["objectid"] for component in solution_components_data.get("value", [])
            if component.get("componenttype") == 1  # ComponentType 1 corresponds to entities
        ]

        # Fetch the logical name of each objectID in the solution_entity_logical_names
        filtered_entities = []
        table_fields = {}
        for object_id in solution_entity_logical_names:
            # Fetch the logical name of the entity
            entity_action = f"EntityDefinitions({object_id})?$select=LogicalName"
            entity_response = fetch_data(f"{endpoint}/{entity_action}", headers)
            entity_data = entity_response
            if "LogicalName" in entity_data:
                filtered_entities.append(entity_data)
                logical_name = entity_data["LogicalName"]

            # Fetch all fields (attributes) for the entity
            fields_action = f"EntityDefinitions(LogicalName='{logical_name}')/Attributes"
            fields_response = fetch_data(f"{endpoint}/{fields_action}", headers)
            table_fields[logical_name] = process_fields(fields_response.get("value", []), definitions_dict)

        # Initialize schema as a dictionary
        schema = {"value": filtered_entities}

        # Extract logical names from the schema
        logical_names = sorted([entity["LogicalName"] for entity in schema.get("value", []) if "LogicalName" in entity])
        # Create a DataFrame with logical names
        df = pd.DataFrame(logical_names, columns=["Logical Names"])
        
        # Save the DataFrame and table fields to an Excel file
        excel_file = "logical_names.xlsx"
        # Check if the file already exists
        # if os.path.exists(excel_file):
        #     print(f"File {excel_file} already exists. Please delete it or choose a different name.")
        #     return

        with pd.ExcelWriter(excel_file, engine="xlsxwriter") as writer:
            # Write logical names to the first sheet
            df.to_excel(writer, sheet_name="Logical Names", index=False)
            
            # Write each table's fields to a separate sheet
            for logical_name, fields in table_fields.items():
            # Combine DataFrame creation and sorting
                fields_df = pd.json_normalize(fields).sort_values(by="ColumnNumber", na_position="last")
                fields_df.to_excel(writer, sheet_name=logical_name[:31], index=False)  # Sheet names are limited to 31 chars
            # Reorder the tabs in the workbook to be in alphabetical order
            workbook = writer.book
            worksheet = writer.sheets["Logical Names"]
            for row_num, logical_name in enumerate(logical_names, start=1):
                worksheet.write_url(f"A{row_num + 1}", f"internal:'{logical_name[:31]}'!A1", string=logical_name)

            # Simplify sheet_order creation
            sheet_order = ["Logical Names"] + sorted(name[:31] for name in table_fields.keys())
            workbook.worksheets_objs.sort(key=lambda ws: sheet_order.index(ws.name))

        print(f"Logical Names and table fields saved to {excel_file}")
        
    except requests.exceptions.RequestException as e:
        print(f"Error fetching schema: {e}")
    except Exception as e:
        print(f"Error writing schema to file: {e}")


def get_env_variable(var_name):
    """
    Retrieve the value of an environment variable.

    Args:
        var_name (str): The name of the environment variable to retrieve.

    Returns:
        str: The value of the specified environment variable.

    Raises:
        Exception: If the environment variable is not set or its value is empty.
    """
    value = os.getenv(var_name)
    if not value:
        raise Exception(f"Environment variable '{var_name}' is not set.")
    return value


# Example usage
if __name__ == "__main__":
    dataverse_url = "https://gamap-dev.crm9.dynamics.com"
    scope = f"{dataverse_url}/.default"
    output_file = "dataverse_schema.json"

    client_id = get_env_variable("client_id")
    client_secret = get_env_variable("client_secret")
    tenant_id = get_env_variable("tenant_id")
    
    try:
        access_token = get_access_token(client_id, tenant_id, client_secret, scope)
        export_dataverse_schema(dataverse_url, access_token, output_file)
    except Exception as e:
        print(f"Error: {e}")